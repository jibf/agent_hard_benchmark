{
  "timestamp": "20250817_201353",
  "model": "/eic/data/rishi/.cache/huggingface/hub/models--Qwen--Qwen3-32B/snapshots/9216db5781bf21249d130ec9da846c4624c16137",
  "client": "OpenAI",
  "total_benchmarks": 14,
  "benchmarks": [
    {
      "benchmark_name": "NVDLibraryBenchmark",
      "metrics": {
        "Accuracy": 0.48717948717948717
      },
      "time_taken_s": 212.9763035774231,
      "total_samples": 78,
      "successful_samples": 78,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "VirusTotalBenchmark",
      "metrics": {
        "Accuracy": 0.7350993377483444
      },
      "time_taken_s": 280.99488520622253,
      "total_samples": 151,
      "successful_samples": 151,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ITType0Benchmark",
      "metrics": {
        "Accuracy": 0.5225225225225225
      },
      "time_taken_s": 224.0800437927246,
      "total_samples": 111,
      "successful_samples": 111,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ITType1Benchmark",
      "metrics": {
        "Accuracy": 0.6
      },
      "time_taken_s": 255.79911613464355,
      "total_samples": 125,
      "successful_samples": 125,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "TicketTracking",
      "metrics": {
        "Accuracy": 0.46153846153846156
      },
      "time_taken_s": 129.2014660835266,
      "total_samples": 91,
      "successful_samples": 91,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainMath",
      "metrics": {
        "Accuracy": 0.55,
        "Max Turns Hit": 0.05,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 341.03386664390564,
      "total_samples": 20,
      "successful_samples": 20,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainRelational",
      "metrics": {
        "Accuracy": 0.9,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 109.91178870201111,
      "total_samples": 20,
      "successful_samples": 20,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "MultiverseMathHard",
      "metrics": {
        "Accuracy": 0.13,
        "Max Turns Hit": 0.08,
        "Invalid Plan": 0.03
      },
      "time_taken_s": 8677.356305599213,
      "total_samples": 100,
      "successful_samples": 100,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainMultitoolTypeWriterHard",
      "metrics": {
        "Accuracy": 0.7666666666666667,
        "Max Turns Hit": 0.16666666666666666,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 7478.699512004852,
      "total_samples": 30,
      "successful_samples": 30,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainTypeWriterHard",
      "metrics": {
        "Accuracy": 0.5,
        "Max Turns Hit": 0.16666666666666666,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 3177.1787803173065,
      "total_samples": 30,
      "successful_samples": 30,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ClimateBenchmark",
      "metrics": {
        "Accuracy": 0.5583756345177665,
        "Max Turns Hit": 0.030456852791878174,
        "Invalid Plan": 0.005076142131979695
      },
      "time_taken_s": 6185.454216718674,
      "total_samples": 197,
      "successful_samples": 197,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "TMIHallucination",
      "metrics": {
        "Accuracy": 0.8360655737704918
      },
      "time_taken_s": 529.8911974430084,
      "total_samples": 61,
      "successful_samples": 61,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "CVECPEBenchmark",
      "metrics": {
        "Accuracy": 0.5,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.03571428571428571
      },
      "time_taken_s": 1463.2042593955994,
      "total_samples": 56,
      "successful_samples": 56,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "VirusTotalAgentic",
      "metrics": {
        "Accuracy": 0.24074074074074073,
        "Max Turns Hit": 0.018518518518518517,
        "Invalid Plan": 0.07407407407407407
      },
      "time_taken_s": 2118.1928532123566,
      "total_samples": 54,
      "successful_samples": 54,
      "error_samples": 0,
      "success_rate": 1.0
    }
  ]
}