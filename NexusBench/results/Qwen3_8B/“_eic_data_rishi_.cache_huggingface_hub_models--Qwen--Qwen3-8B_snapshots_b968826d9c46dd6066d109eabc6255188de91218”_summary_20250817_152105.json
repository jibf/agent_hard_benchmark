{
  "timestamp": "20250817_152105",
  "model": "\u201c/eic/data/rishi/.cache/huggingface/hub/models--Qwen--Qwen3-8B/snapshots/b968826d9c46dd6066d109eabc6255188de91218\u201d",
  "client": "OpenAI",
  "total_benchmarks": 14,
  "benchmarks": [
    {
      "benchmark_name": "NVDLibraryBenchmark",
      "metrics": {
        "Accuracy": 0.5769230769230769
      },
      "time_taken_s": 159.36796975135803,
      "total_samples": 78,
      "successful_samples": 78,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "VirusTotalBenchmark",
      "metrics": {
        "Accuracy": 0.7284768211920529
      },
      "time_taken_s": 236.60995507240295,
      "total_samples": 151,
      "successful_samples": 151,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ITType0Benchmark",
      "metrics": {
        "Accuracy": 0.26126126126126126
      },
      "time_taken_s": 150.261705160141,
      "total_samples": 111,
      "successful_samples": 111,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ITType1Benchmark",
      "metrics": {
        "Accuracy": 0.472
      },
      "time_taken_s": 263.56976437568665,
      "total_samples": 125,
      "successful_samples": 125,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "TicketTracking",
      "metrics": {
        "Accuracy": 0.3956043956043956
      },
      "time_taken_s": 164.63242173194885,
      "total_samples": 91,
      "successful_samples": 91,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainMath",
      "metrics": {
        "Accuracy": 0.6,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 115.44251585006714,
      "total_samples": 20,
      "successful_samples": 20,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainRelational",
      "metrics": {
        "Accuracy": 0.9,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 104.78209352493286,
      "total_samples": 20,
      "successful_samples": 20,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "MultiverseMathHard",
      "metrics": {
        "Accuracy": 0.09,
        "Max Turns Hit": 0.13,
        "Invalid Plan": 0.03
      },
      "time_taken_s": 5989.04882645607,
      "total_samples": 100,
      "successful_samples": 100,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainMultitoolTypeWriterHard",
      "metrics": {
        "Accuracy": 0.8,
        "Max Turns Hit": 0.13333333333333333,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 4142.874361276627,
      "total_samples": 30,
      "successful_samples": 30,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "LangChainTypeWriterHard",
      "metrics": {
        "Accuracy": 0.4666666666666667,
        "Max Turns Hit": 0.1,
        "Invalid Plan": 0.0
      },
      "time_taken_s": 2767.823707342148,
      "total_samples": 30,
      "successful_samples": 30,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "ClimateBenchmark",
      "metrics": {
        "Accuracy": 0.5532994923857868,
        "Max Turns Hit": 0.005076142131979695,
        "Invalid Plan": 0.01015228426395939
      },
      "time_taken_s": 3079.888552427292,
      "total_samples": 197,
      "successful_samples": 197,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "TMIHallucination",
      "metrics": {
        "Accuracy": 0.7377049180327869
      },
      "time_taken_s": 419.17539048194885,
      "total_samples": 61,
      "successful_samples": 61,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "CVECPEBenchmark",
      "metrics": {
        "Accuracy": 0.375,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.017857142857142856
      },
      "time_taken_s": 886.8389801979065,
      "total_samples": 56,
      "successful_samples": 56,
      "error_samples": 0,
      "success_rate": 1.0
    },
    {
      "benchmark_name": "VirusTotalAgentic",
      "metrics": {
        "Accuracy": 0.25925925925925924,
        "Max Turns Hit": 0.0,
        "Invalid Plan": 0.05555555555555555
      },
      "time_taken_s": 643.860773563385,
      "total_samples": 54,
      "successful_samples": 54,
      "error_samples": 0,
      "success_rate": 1.0
    }
  ]
}